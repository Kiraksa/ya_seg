# Сегментация изображений (UNet + MMSegmentation)

## Этап 1. Исследовательский анализ (EDA)

### Анализ качества данных 

**Структура датасета**

Данные хранятся в формате MMSegmentation в папке data/practicum_dataset:

```text
data/
  img/
    train/
    val/
    test/
  labels/
    train/
    val/
    test/
```

В practicum_work/src/data лежат серипты, используемые для проверки согласованности имен файлов и оценки дисбаланса классов.
Все файлы присутствовали.
С помощью скрипта practicum_work/overlay_masks.py было произведено наложение маск на изображения. В ходе анализы было выяснено, что 15 маск были сильно неточными: либо не включают важные элементы объекта, либо наоборот выделяют объект крупным пятном. Оценка производилась визуально.
В силу ограниченного времени и усталости, в том числе от этого проекта, было принято решение удалить деффектные сэмплы, а не доразмечать. Так как данных для обучения в таком случае мало (осталось всего 185), это скорее всего повлияло на качество результатов сегментации.
Сами оверлеи лежат в папке practicum_work/overlays


### EDA

Что касается классов, их три: фон, собака, кошка. Эти классы распределены примерно в соотношении 90:5:5.
Все изображения 256*256.

---

## Этап 2. Формирование первичных гипотез

### Стартовая гипотеза 1 

**Описание гипотезы**  

Для первой гипотезы была выбрана базовая модель:

- архитектура: UNet (FCN на базе UNet) из MMSegmentation;
- входной размер: 256×256;
- функции потерь:
  - `CrossEntropyLoss` без весов классов;
  - `DiceLoss` с весом 3.0;
- оптимизатор: `AdamW(lr=1e-3, weight_decay=0.1)`;
- scheduler: `PolyLR` (polynomial decay), 300 эпох;
- аугментации:
  - `Resize(scale=(256, 256), keep_ratio=False)`;
  - `RandomFlip` (горизонтальный/вертикальный);
  - лёгкий `PhotoMetricDistortion` (по умолчанию).

Логика выбора:

- UNet хорошо работает на задачах сегментации с небольшим количеством классов и ограниченным количеством данных.
- CE + Dice — стандартный набор для задач с дисбалансом классов, Dice помогает лучше сегментировать малые объекты.
- Аугментации минимальные, чтобы сначала получить стабильный базовый уровень качества.

**Результаты обучения**  

- Конфиг: `configs/practicum/unet_fcn-256.py`  
- ClearML эксперимент: (https://app.clear.ml/projects/79923fb0f864434fa1f54856d7bf7bb3/experiments/c6e7b5c731e44cefa6a9e2b8e86edc90/output/execution)

Графики кривой ошибки сохранены:

- `work_dirs/unet_fcn-256/plots`   

**Анализ качества**  

Скрипты анализа:

- `src/analysis/plot_training_curves.py` — сохранил кривую ошибки на обуении;
- `src/analysis/infer_unet_fcn.py` — посчитал mDice по каждому примеру и сохранил top-10 лучших/худших предсказаний.

Наблюдения:

- Модель неплохо сегментирует крупные объекты;
- Ошибается на границах: сдвигает их или расширяет

Примеры:

- Удачные предсказания: `practicum_work/outputs/unet_val_eval/top10_best_mdice/*.png`
- Неудачные: `practicum_work/outputs/unet_val_eval/top10_worst_mdice/*.png`
- Результаты тестовой выборки: `practicum_work/outputs/unet_test_vis/*.png`

### Остальные гипотезы 

**Описание гипотезы**  

Обучение ведется агрессивно, поэтому уменьшим lr до -4 порядка, как и weight_decay. Увсилим вклад Dice. А так же учтем дисбаланс классов, обозначив отдельные веса для каждого класса в обратном соотношении от частоты (и отнормировав). Так же была добавлена аугментация по яркости, контрастности, тональности. Результаты слеующих 4 исследований лежат в аналогичных директориях с припиской `_v{num}`. 

**Результаты обучения**

- Конфиг: `configs/practicum/unet_fcn-256_v{num}.py`  
- ClearML эксперимент: 
- - https://app.clear.ml/projects/79923fb0f864434fa1f54856d7bf7bb3/experiments/25b545dc7888494f854b1275db513da5/output/execution
- - https://app.clear.ml/projects/79923fb0f864434fa1f54856d7bf7bb3/experiments/a395399715524ac8bc1e93a559d35b67/output/execution
- - https://app.clear.ml/projects/79923fb0f864434fa1f54856d7bf7bb3/experiments/99037f3d58ec4839b4440676049a32ca/output/execution
- - https://app.clear.ml/projects/79923fb0f864434fa1f54856d7bf7bb3/experiments/e12f1ccd04e848fabe378706f054d2a2/output/execution


---

## Заключение

Мне кажется, что никакой эксперимент не удался. Все случаи показали mDice < 0.75.

Причины:
- Малое количество данных, некачественная разметка
- Неверный выбор гиперпараметров

Не было бы у меня работы и учебы, то можно было бы провести более глубокий анализ данной задачи, пусть она и не такая уж громоздкая. Однако я и так просрочил дедлайн.

Отмечу так же, что хоть в данном спринте описание работы с OpenMMLab более подробное, этого недостаточно для полного погружения в эту "утилиту". Лично мне пришлось изрядно постараться, чтобы разобраться в правилах этих конфигураций, в том числе прибегнуть к ии-чатам. В курсе хорошо изложена теория того, как устроены эти алгоритмы, архитектуры, за это спасибо. Однако этого недостаточно для того, чтобы использовать какой-то отдельный фреймворк (я не знаю как это назвать). Однако спасибо за знакомство, ведь раньше я действительно писал все модели с нуля, опираясь на статьи. После курса буду разбираться подробнее, чтобы в будущем облегчить себе жизнь таким образом.

---

## Документация кода

Данный репозиторий находился внутри mmsegmentation. Выложены тоьько кастомные части

Структура проекта:

```text
practicum_work
├── README.md
├── outputs
│   ├── unet_test_vis
│   ├── unet_val_eval
│   ├── . . .
├── overlays
│   ├── train
│   ├── val
├── work_dirs
│   ├── unet_fcn-256
│   ├── unet_fcn-256_v2
│   ├── unet_fcn-256_v3
│   ├── unet_fcn-256_v4
│   ├── unet_fcn-256_v5
├── src
│   ├── data
│   │   ├── mmseg_to_coco.py 
│   │   │   # конвертация в формат COCO для загрузки в CVAT
│   │   ├── coco_to_mmseg.py 
│   │   │   # конвертация в формат mmsegmentation из COCO, 
│   │   │   # для использования датасета после доразметки
│   │   ├── analysis.py
│   │   │   # проверка согласованности img/labels + визуализация пар
│   │   ├── data_stats.py 
│   │   │   # генерация графиков для EDA (баланс классов, размеры картинок и т.д.)
│   ├── analysis 
│   │   ├── infer_unet_fcn.py 
│   │   │   # сохранить предсказания модели на датасете (маски и оверлеи)
│   │   │   # сохранить примеры лучших и худших предсказаний
│   │   │   # по индивидуальному mDice для каждого сэмпла
│   │   ├── plot_training_curves.py
│   │   │   # построение train loss и val metrics из *.log.json mmseg
├── solution.ipynb
├── overlay_masks.py
```
